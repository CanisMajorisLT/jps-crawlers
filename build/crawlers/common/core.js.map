{"version":3,"sources":["crawlers/common/core.js"],"names":[],"mappings":";;;;;;;;;;;;;;;;wDA6DO,iBAAqC,GAArC,EAA0C,MAA1C;AAAA,YAEK,IAFL;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+BAEkB,yBAAY,GAAZ,CAFlB;;AAAA;AAEK,4BAFL;AAAA,yDAGQ,SAAS,OAAO,IAAP,CAAT,CAHR;;AAAA;AAAA;AAAA;;AAKC,yCAAO,KAAP,CAAa,mCAAb;;AALD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,K;;oBAAe,qB;;;;;;;;;;;;;;QAfN,sB,GAAA,sB;QA+BA,6B,GAAA,6B;QAUA,wB,GAAA,wB;QAYA,wB,GAAA,wB;;AAnGhB;;AACA;;;;AACA;;AACA;;AACA;;;;;;;;AAEA,IAAM,qBAAqB,IAA3B;AACA,IAAM,uBAAuB,CAA7B;AACA,IAAM,qBAAqB,CAA3B;AACA,IAAM,8BAA8B,GAApC;;AAEA,IAAM,gBAAgB;AAClB,0CADkB;AAElB,8CAFkB;AAGlB,0CAHkB;AAIlB;AAJkB,CAAtB;;;;;;;;;AAeA,SAAS,qBAAT,CAA+B,UAA/B,EAA2C,UAA3C,EAA+E;AAAA,QAAxB,MAAwB,yDAAf,aAAe;;AAC3E,WAAO;AACH,8BADG;AAEH,iBAAS,0BAAc,CAAd,CAFN;AAGH,iBAAS,OAAO,oBAHb,E;AAIH,uBAAe,CAJZ,E;AAKH,eAAO,OAAO,kBALX,E;AAMH,uBAAe,OAAO,2BANnB,E;AAOH,eAAO,OAAO,kBAPX,E;AAQH;AARG,KAAP;AAUH;;;;;;;;;AASM,SAAS,sBAAT,CAAgC,CAAhC,EAA2D;AAAA,QAAxB,UAAwB,yDAAX,CAAW;AAAA,QAAR,MAAQ;;AAC9D,QAAM,QAAQ,EAAd;AACA,SAAK,IAAI,IAAI,UAAb,EAAyB,KAAK,CAA9B,EAAiC,GAAjC,EAAsC;AAClC,cAAM,IAAN,CAAW,sBAAsB,CAAtB,EAAyB,MAAM,CAA/B,EAAkC,MAAlC,CAAX;AACH;;AAED,WAAO,KAAP;AACH,CAwBM,SAAS,6BAAT,CAAuC,GAAvC,EAA4C,MAA5C,EAAoD;;AAEvD;AAAA,4DAAO,kBAA8B,IAA9B;AAAA,gBACG,OADH,EAEG,IAFH;AAAA;AAAA;AAAA;AAAA;AACG,mCADH,GACa,IAAI,OAAJ,CAAY,SAAZ,EAAuB,KAAK,UAA5B,CADb;AAAA;AAAA,mCAEgB,yBAAY,OAAZ,CAFhB;;AAAA;AAEG,gCAFH;AAAA,8DAII,OAAO,IAAP,EAAa,IAAb,CAJJ;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAAP;;AAAA,iBAAsB,cAAtB;AAAA;AAAA;;AAAA,eAAsB,cAAtB;AAAA;AAMH;;AAEM,SAAS,wBAAT,CAAkC,IAAlC,EAAwC,QAAxC,EAAkD;AACrD,WAAO,SAAS,iBAAT,OAAyD;AAAA,YAArB,MAAqB,QAA7B,MAA6B;AAAA,YAAP,IAAO,QAAb,IAAa;;AAC5D,yBAAO,IAAP,CAAe,IAAf,qDAAmE,KAAK,UAAxE;;;AAGA,oBAAY,SAAS,MAAT,EAAiB,IAAjB,EAAuB,IAAvB,CAAZ;AACH,KALD;AAMH;;AAKM,SAAS,wBAAT,CAAkC,IAAlC,EAAwC;AAC3C,QAAI,cAAJ;;AAEA,aAAS,iBAAT,QAAuD;AAAA,YAApB,KAAoB,SAA3B,KAA2B;AAAA,YAAP,IAAO,SAAb,IAAa;;AACnD,yBAAO,KAAP,CAAgB,IAAhB,mBAAoC,EAAC,YAAD,EAAQ,UAAR,EAApC;AACA,YAAI,KAAK,OAAL,IAAgB,KAAK,OAAL,GAAe,CAA/B,IAAqC,KAAK,aAAL,GAAqB,KAAK,OAAnE,EAA6E;AACzE,cAAE,KAAK,aAAP;;AAEA,kBAAM,IAAN,CAAW,IAAX;AACH,SAJD,MAIO;AACH,6BAAO,KAAP,CAAa,mDAAb;AACH;AACJ;;AAED,WAAO;AACH,iBAAS,iBADN;AAEH,kBAAU,kBAAC,CAAD,EAAM;AAAC,oBAAQ,CAAR;AAAU;AAFxB,KAAP;AAIH","file":"crawlers/common/core.js","sourcesContent":["import { getPageBody } from './scrape'\r\nimport { default as async_ } from 'async'\r\nimport { datePlusHours } from './utils'\r\nimport { queueWorkerFactory } from './queueWorkerFactory'\r\nimport logger from '../../../logging/logger'\r\n\r\nconst DEFAULT_TASK_DELAY = 1000;\r\nconst DEFAULT_TASK_REQUEUE = 5;\r\nconst DEFAULT_TASK_RETRY = 3;\r\nconst DEFAULT_TASK_RETRY_INTERVAL = 200;\r\n\r\nconst defaultConfig = {\r\n    DEFAULT_TASK_DELAY,\r\n    DEFAULT_TASK_REQUEUE,\r\n    DEFAULT_TASK_RETRY,\r\n    DEFAULT_TASK_RETRY_INTERVAL\r\n};\r\n\r\n\r\n/**\r\n * Generates object used for doing parse task\r\n * @param pageNumber\r\n * @param {boolean} isLastPage\r\n * @param {object=} config\r\n * @returns {{pageNumber: *, expires: *, requeue: number, timesRequeued: number, retry: number, retryInterval: number, delay: number}}\r\n */\r\nfunction generateFrontInfoTask(pageNumber, isLastPage, config = defaultConfig) {\r\n    return {\r\n        pageNumber,\r\n        expires: datePlusHours(1),\r\n        requeue: config.DEFAULT_TASK_REQUEUE, // optional\r\n        timesRequeued: 0, // optional\r\n        retry: config.DEFAULT_TASK_RETRY, // optional\r\n        retryInterval: config.DEFAULT_TASK_RETRY_INTERVAL, // optional\r\n        delay: config.DEFAULT_TASK_DELAY, //optional\r\n        isLastPage\r\n    }\r\n}\r\n\r\n/**\r\n * Generates n number of tasks for worker\r\n * @param {number} n\r\n * @param {number=0} startIndex\r\n * @param {object} config\r\n * @returns {Array}\r\n */\r\nexport function generateFrontInfoTasks(n, startIndex = 0, config) {\r\n    const tasks = [];\r\n    for (var i = startIndex; i <= n; i++) {\r\n        tasks.push(generateFrontInfoTask(i, i === n, config))\r\n    }\r\n\r\n    return tasks\r\n}\r\n\r\n/**\r\n * Parses given uri with provided parser to get number of pages to parse\r\n * @param {string} uri\r\n * @param {function} parser\r\n * @returns {Number}\r\n */\r\nexport async function getNumberOfFrontPages(uri, parser) {\r\n    try {\r\n        let html = await getPageBody(uri);\r\n        return parseInt(parser(html));\r\n    } catch (error) {\r\n        logger.error('getNumberOfFrontPages threw error', error);\r\n    }\r\n}\r\n\r\n/**\r\n * Parses given page to extract all info about ads.\r\n * Used as task in queue worker.\r\n * @param {string} uri\r\n * @param {function} parser\r\n * @returns {function} parseFrontPage\r\n */\r\nexport function parseFrontPageArticlesFactory(uri, parser) {\r\n\r\n    return async function parseFrontPage(task) {\r\n        const fullUri = uri.replace('${page}', task.pageNumber);\r\n        const html = await getPageBody(fullUri);\r\n\r\n        return parser(html, task);\r\n    }\r\n}\r\n\r\nexport function handleTaskSuccessFactory(site, callback) {\r\n    return function handleTaskSuccess({result: result, task: task}) {\r\n        logger.info(`${site} Successfully finished parsing front page nr ${task.pageNumber}`);\r\n\r\n        // write to DB\r\n        callback && callback(result, site, task)\r\n    }\r\n}\r\n\r\n\r\n\r\n\r\nexport function handleTaskFailureFactory(site) {\r\n    let queue;\r\n\r\n    function handleTaskFailure({error: error, task: task}) {\r\n        logger.error(`${site} Task failed`, {error, task});\r\n        if (task.requeue && task.requeue > 0 && (task.timesRequeued < task.requeue)) {\r\n            ++task.timesRequeued;\r\n\r\n            queue.push(task)\r\n        } else {\r\n            logger.debug('Task failed too many times, all requeues exausted');\r\n        }\r\n    }\r\n\r\n    return {\r\n        handler: handleTaskFailure,\r\n        setQueue: (q)=> {queue = q}\r\n    }\r\n}\r\n\r\n\r\n\r\n"],"sourceRoot":"/source/"}