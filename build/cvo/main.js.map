{"version":3,"sources":["../../src/crawlers/cvo/main.js"],"names":[],"mappings":";;;;;;;;;wDA6CA;YAEY;;;;;;;+BAAa,yBAAY,eAAe,OAAf,CAAuB,SAAvB,EAAkC,KAAlC,CAAZ;;;AAAb;yDACG,SAAS,mCAAsB,IAAtB,CAAT;;;;;;AAEP,gCAAQ,GAAR,CAAY,mCAAZ;;;;;;;;KALR;;oBAAe;;;;;;;;;;;;;;wDAef,kBAA8B,IAA9B;YACU,YACA,KACA;;;;;AAFA,qCAAa,KAAK,UAAL;AACb,8BAAM,eAAe,OAAf,CAAuB,SAAvB,EAAkC,UAAlC;;+BACO,yBAAY,GAAZ;;;AAAb;0DAEC,8BAAiB,IAAjB;;;;;;;;KALX;;oBAAe;;;;;;wDAwCf;YACQ,gBAEE,QACA,wBAIA,OAGA;;;;;AAVF,yCAAiB;AAEf,iCAAS,4CAAmB,cAAnB,EAAmC,eAAe,OAAf,EAAwB,iBAA3D;AACT,iDAAyB,gBAAO,KAAP,CAAa,MAAb,EAAqB,sBAArB;;;AAE/B,uCAAe,QAAf,CAAwB,sBAAxB;;;+BAEoB;;;AAAd;;AACN,gCAAQ,GAAR,kBAA2B,KAA3B;;AAEM,gCAAQ,2BAA2B,KAA3B;;;AAEd,+CAAuB,IAAvB,CAA4B,KAA5B;;;;;;;;KAbJ;;oBAAe;;;;;;;;;;;;;;;;;;;;;AA9Ff,IAAM,iBAAiB,0DAAjB;AACN,IAAM,yBAAyB,CAAzB;AACN,IAAM,qBAAqB,IAArB;AACN,IAAM,uBAAuB,CAAvB;AACN,IAAM,qBAAqB,CAArB;AACN,IAAM,8BAA8B,GAA9B;;;;;;;AAQN,SAAS,qBAAT,CAA+B,UAA/B,EAA2C;AACvC,WAAO;AACH,8BADG;AAEH,iBAAS,0BAAc,CAAd,CAAT;AACA,iBAAS,oBAAT;AACA,uBAAe,CAAf;AACA,eAAO,kBAAP;AACA,uBAAe,2BAAf;AACA,eAAO,kBAAP;AAPG,KAAP,CADuC;CAA3C;;AAYA,SAAS,0BAAT,CAAoC,CAApC,EAAuC;AACnC,QAAM,QAAQ,EAAR,CAD6B;AAEnC,SAAK,IAAI,IAAI,CAAJ,EAAO,KAAK,CAAL,EAAQ,GAAxB,EAA6B;AACzB,cAAM,IAAN,CAAW,sBAAsB,CAAtB,CAAX,EADyB;KAA7B;;AAIA,WAAO,KAAP,CANmC;CAAvC;;AAwCA,SAAS,iBAAT,OAAyD;QAArB,cAAR,OAA6B;QAAP,YAAN,KAAa;;AACrD,YAAQ,GAAR,kDAA2D,KAAK,UAAL,CAA3D,CADqD;AAErD,YAAQ,GAAR,CAAY,MAAZ;;AAFqD,CAAzD;;AAOA,SAAS,wBAAT,GAAoC;AAChC,QAAI,iBAAJ,CADgC;;AAGhC,aAAS,iBAAT,QAAuD;YAApB,cAAP,MAA2B;YAAP,aAAN,KAAa;;AACnD,gBAAQ,KAAR,CAAc,aAAd,EAA6B,KAA7B,EAAoC,IAApC,EADmD;AAEnD,YAAI,KAAK,OAAL,IAAgB,KAAK,OAAL,GAAe,CAAf,IAAqB,KAAK,aAAL,GAAqB,KAAK,OAAL,EAAe;AACzE,cAAE,KAAK,aAAL,CADuE;;AAGzE,kBAAM,IAAN,CAAW,IAAX,EAHyE;SAA7E,MAIO;;SAJP;KAFJ;;AAWA,WAAO;AACH,iBAAS,iBAAT;AACA,kBAAU,kBAAC,CAAD,EAAM;AAAC,oBAAQ,CAAR,CAAD;SAAN;KAFd,CAdgC;CAApC;;AAsCA","file":"main.js","sourcesContent":["import { getPageBody } from '../common/scrape'\r\nimport { default as async_ } from 'async'\r\nimport { extractTotalPageCount, extractFrontInfo } from './parser'\r\nimport { datePlusHours } from '../common/utils'\r\nimport { queueWorkerFactory } from '../common/queueWorkerFactory'\r\n\r\nconst FRONT_PAGE_URI = 'http://www.cvonline.lt/darbo-skelbimai/visi?page=${page}';\r\nconst DEFAULT_WORKERS_NUMBER = 1;\r\nconst DEFAULT_TASK_DELAY = 1000;\r\nconst DEFAULT_TASK_REQUEUE = 5;\r\nconst DEFAULT_TASK_RETRY = 3;\r\nconst DEFAULT_TASK_RETRY_INTERVAL = 200;\r\n\r\n\r\n/**\r\n * Generates object used for doing parse task\r\n * @param pageNumber\r\n * @returns {{pageNumber: *, expires: *, requeue: number, timesRequeued: number, retry: number, retryInterval: number, delay: number}}\r\n */\r\nfunction generateFrontInfoTask(pageNumber) {\r\n    return {\r\n        pageNumber,\r\n        expires: datePlusHours(1),\r\n        requeue: DEFAULT_TASK_REQUEUE, // optional\r\n        timesRequeued: 0, // optional\r\n        retry: DEFAULT_TASK_RETRY, // optional\r\n        retryInterval: DEFAULT_TASK_RETRY_INTERVAL, // optional\r\n        delay: DEFAULT_TASK_DELAY //optional\r\n    }\r\n}\r\n\r\nfunction generateManyFrontInfoTasks(n) {\r\n    const tasks = [];\r\n    for (var i = 0; i <= n; i++) {\r\n        tasks.push(generateFrontInfoTask(i))\r\n    }\r\n\r\n    return tasks\r\n}\r\n\r\n/**\r\n * Parses page further enough that it has no ads, but link to last page with ads\r\n * and thus returns total number of pages with ads.\r\n * @returns {Number}\r\n */\r\nasync function getNumberOfFrontPages() {\r\n    try {\r\n        let html = await getPageBody(FRONT_PAGE_URI.replace('${page}', '200'));\r\n        return parseInt(extractTotalPageCount(html));\r\n    } catch (error) {\r\n        console.log('getNumberOfFrontPages threw error', error);\r\n    }\r\n}\r\n\r\n/**\r\n * Parses given page n to extract all info about ads.\r\n * Used as task in queue worker\r\n * @param task\r\n * @returns {*}\r\n */\r\nasync function parseFrontPage(task) {\r\n    const pageNumber = task.pageNumber;\r\n    const uri = FRONT_PAGE_URI.replace('${page}', pageNumber);\r\n    const html = await getPageBody(uri);\r\n\r\n    return extractFrontInfo(html);\r\n\r\n\r\n}\r\n\r\n\r\nfunction handleTaskSuccess({result: result, task: task}) {\r\n    console.log(`Successfully finished parsing front page nr ${task.pageNumber}`);\r\n    console.log(result);\r\n    // write to DB, pass down for metadata add\r\n}\r\n\r\n\r\nfunction handleTaskFailureWrapper() {\r\n    let queue;\r\n\r\n    function handleTaskFailure({error: error, task: task}) {\r\n        console.error('Task failed', error, task);\r\n        if (task.requeue && task.requeue > 0 && (task.timesRequeued < task.requeue)) {\r\n            ++task.timesRequeued;\r\n\r\n            queue.push(task)\r\n        } else {\r\n            // log error so somethere\r\n        }\r\n    }\r\n\r\n    return {\r\n        handler: handleTaskFailure,\r\n        setQueue: (q)=> {queue = q}\r\n    }\r\n}\r\n\r\n\r\n\r\nasync function parseCVO() {\r\n    let handleTaskFail = handleTaskFailureWrapper();\r\n\r\n    const worker = queueWorkerFactory(parseFrontPage, handleTaskFail.handler, handleTaskSuccess);\r\n    const FrontInfoFetchingQueue = async_.queue(worker, DEFAULT_WORKERS_NUMBER);\r\n\r\n    handleTaskFail.setQueue(FrontInfoFetchingQueue); // so task can be requeued on fail\r\n\r\n    const pages = await getNumberOfFrontPages();\r\n    console.log(`Page count: ${pages}`);\r\n\r\n    const tasks = generateManyFrontInfoTasks(pages);\r\n\r\n    FrontInfoFetchingQueue.push(tasks)\r\n}\r\n\r\nparseCVO();\r\n\r\n\r\n"]}